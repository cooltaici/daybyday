# Rethinking Atrous Convolution for Semantic Image Segmentation
**地址**：https://arxiv.org/abs/1706.05587
**Tesorflow 源代码**:https://github.com/NanqingD/DeepLabV3-Tensorflow
**Keras 源代码** :https://github.com/Shmuelnaaman/deeplab_v3
**其它资料**：https://blog.csdn.net/u011974639/article/details/79144773
**摘要**：
&emsp;DeepLabv3进一步探讨空洞卷积，这是一个在语义分割任务中：可以调整滤波器视野、控制卷积神经网络计算的特征响应分辨率的强大工具。为了解决多尺度下的目标分割问题，我们设计了空洞卷积级联或不同采样率空洞卷积并行架构。此外，我们强调了ASPP(Atrous Spatial Pyramid Pooling)模块，该模块可以在获取多个尺度上卷积特征，进一步提升性能。同时，我们分享了实施细节和训练方法，此次提出的DeepLabv3相比先前的版本有显著的效果提升，在PASCAL VOC 2012上获得了先进的性能。
### Introduction
DeepLabv3的主要贡献在于：
- 本文重新讨论了空洞卷积的使用，这让我们在级联模块和空间金字塔池化的框架下，能够获取更大的感受野从而获取多尺度信息。
- 改进了ASPP模块：由不同采样率的空洞卷积和BN层组成，我们尝试以级联或并行的方式布局模块。
- 讨论了一个重要问题：使用大采样率的3×3的空洞卷积，因为图像边界响应无法捕捉远距离信息，会退化为1×1的卷积, 我们建议将图像级特征融合到ASPP模块中。
- 阐述了训练细节并分享了训练经验，论文提出的”DeepLabv3”改进了以前的工作，获得了很好的结果。
### Related Work
&emsp;现有多个工作表明全局特征或上下文之间的互相作用有助于做语义分割，我们讨论四种不同类型利用上下文信息做语义分割的全卷积网络。
&emsp;**图像金字塔(Image pyramid)**： 通常使用共享权重的模型，适用于多尺度的输入。小尺度的输入响应控制语义，大尺寸的输入响应控制细节。通过拉布拉斯金字塔对输入变换成多尺度，传入DCNN，融合输出。这类的缺点是：因为GPU存储器的限制，对于更大/更深的模型不方便扩展。通常应用于推断阶段。
&emsp;**编码器-解码器(Encoder-decoder)**： 编码器的高层次的特征容易捕获更长的距离信息，在解码器阶段使用编码器阶段的信息帮助恢复目标的细节和空间维度。例如SegNet利用下采样的池化索引作为上采样的指导；U-Net增加了编码器部分的特征跳跃连接到解码器；RefineNet等证明了Encoder-Decoder结构的有效性。
&emsp;**上下文模块(Context module)**：包含了额外的模块用于级联编码长距离的上下文。一种有效的方法是DenseCRF并入DCNN中，共同训练DCNN和CRF。
&emsp;**空间金字塔池化(Spatial pyramid pooling)**：采用空间金字塔池化可以捕捉多个层次的上下文。在ParseNet中从不同图像等级的特征中获取上下文信息；DeepLabv2提出ASPP，以不同采样率的并行空洞卷积捕捉多尺度信息。最近PSPNet在不同网格尺度上执行空间池化，并在多个数据集上获得优异的表现。还有其他基于LSTM方法聚合全局信息。我们的工作主要探讨空洞卷积作为上下文模块和一个空间金字塔池化的工具，这适用于任何网络。具体来说，我们取ResNet最后一个block，复制多个级联起来，送入到ASPP模块后。我们通过实验发现使用BN层有利于训练过程，为了进一步捕获全局上下文，我们建议在ASPP上融入图像级特征.